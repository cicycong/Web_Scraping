# -*- coding: utf-8 -*-
"""Web_Scraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I50yR5VBBmq7H_Wr4x1ebtwhGYwOShaY
"""

# pip install requests

import requests
from bs4 import BeautifulSoup
import json
import csv

first_URL = 'https://www.trustpilot.com/review/www.twitter.com'
page = requests.get(first_URL)
first_soup = BeautifulSoup(page.text, 'html.parser')

#Extract the total number of reviews including all languages
# total_review = soup.find('span', class_='headline__review-count').text
total_review = first_soup.find('h2', class_='header--inline').text.split()[0]
print(total_review)

def parse_url(url):     
    response = requests.get(url)
    content = response.content     
    soup = BeautifulSoup(content, "html.parser")     
    return soup

filename = "twitter_reviews.csv"
f = open(filename, 'w')
headers = "companyName, datePublished, ratingValue, reviewBody\n"
f.write(headers)

base_url = "https://www.trustpilot.com"

#Extract the reviews that are writen in English
url = "https://www.trustpilot.com/review/www.twitter.com"
next_button=""
# count=1

while next_button is not None:
  # print(count)
  # print(url)
  #get the url
  soup = parse_url(url)
  # print(url)
  #find all the review cards in one page
  reviews=soup.find("div",{"class":"review-list"})
  review_cards=reviews.findAll("div",{"class":"review-card"})

  #extract information from each review card
  for review in review_cards:

      companyName = soup.find("div", {"class": "right-section"}).find("span",{"class":"multi-size-header__big"}).text.split()[0]
          
      date=review.find("script",{"data-initial-state":"review-dates"})
      datePublished = json.loads(date.contents[0])['publishedDate']
          
      ratingValue=review.find("div", {"class":"star-rating star-rating--medium"}).find("img")["alt"][0]

      review_body = review.find("p", {"class":"review-content__text"})
      if review_body==None:
        reviewBody="None"
      else:
        reviewBody=review.find("p", {"class":"review-content__text"}).get_text(strip = True)
      
      f.write(companyName + "," + datePublished + "," + ratingValue + "," + reviewBody + '\n')

  next_button=soup.find("nav", {"class": "pagination-container AjaxPager"}).find("a",{"data-page-number":"next-page"})
  if next_button is not None:
    url=base_url+next_button["href"]
    # count+=1

f.close()